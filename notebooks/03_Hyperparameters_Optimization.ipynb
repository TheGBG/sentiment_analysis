{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores: \n",
    "Blanco García, Gabriel: gabriel.blanco@cunef.edu   \n",
    "Ferrín Meilá, Michelle: michelle.ferrin@cunef.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros: regresión logística  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí optimizaremos los hiperparámetros de la logistica, que es nuestro modelo ganador. La optimización de hiperparáemtros consiste en probar múltiples combinaciones de hiperparámetros de un determinado modelo, y seleccionar la combinación que maximice una métrica determinada. Se trata de afinar el modelo, para conseguir sacar el máximo partido de él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones básicas\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "import pickle\n",
    "\n",
    "# Herramientas para optimizar y vectorizar\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# El modelo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Nuestras funciones\n",
    "%run ../src/operar_modelos.ipynb\n",
    "%run ../src/plots_metricas.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../data/train/X_train.sav')\n",
    "y_train = pd.read_pickle('../data/train/y_train.sav')\n",
    "\n",
    "X_validation = pd.read_pickle('../data/validation/X_validation.sav')\n",
    "y_validation = pd.read_pickle('../data/validation/y_validation.sav')\n",
    "\n",
    "X_test = pd.read_pickle('../data/test/X_test.sav')\n",
    "y_test = pd.read_pickle('../data/test/y_test.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo ganador, el cual va a ser optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_logistica = cargar_modelo('../models/trained_models/classifiers/LogisticRegression().sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizador', TfidfVectorizer()),\n",
       "                ('clasificador', LogisticRegression())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion_logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos el vectorizador que forma parte de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que definir el espacio de búsqueda, que consite en los distintos hiperparámetros que queremos probar. Utilizamos un diccionario con la siguiente estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros = {\n",
    "    \n",
    "    # Hay que usar la sintaxis: 'nombre del modelo en el pipe__nombre del hiperparámetro'\n",
    "    'clasificador__penalty': ['l1', 'l2', 'elasticnet'], # los métodos de regularización: lasso, ridge \n",
    "                                                         # y el enfoque mixto\n",
    "    \n",
    "    'clasificador__C': [0.001, 0.01, 0.1, 1, 10, 100], # distintos valores para el parámetro de regularización\n",
    "    \n",
    "    'clasificador__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], # los distintos métodos \n",
    "                                                                                # por los que se estiman los \n",
    "                                                                                # parámetros.\n",
    "    \n",
    "    'clasificador__max_iter': [100, 250, 500, 1000] # distintos limites de iteraciones \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ligereza del modelo puede aprovecharse para exprimir al máximo la optimización de sus hiperparámetros y probar todas las combinaciones posibles con `GridSearchCV()` y una tabla de hiperparémtros generosa, como la que hemos definido. Además, para garantizar la fiabilidad de los resultados, aplicaremos validación cruzada, con 10 folds. La métrica que se utiliza para juzgar las combinaciones de hiperparámetrois es el __área bajo la curva roc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización del objeto de optimización\n",
    "regresion_logistica_optimizada = GridSearchCV(regresion_logistica, # el modelo\n",
    "                                              \n",
    "                                              hiperparametros, # los hiperparámetros definidos\n",
    "                                              \n",
    "                                              scoring='roc_auc', # selección por auc, métrica a maximizar\n",
    "                                              \n",
    "                                              cv=10, # validación cruzada de 10 folds\n",
    "                                              \n",
    "                                              verbose=1, # informacion sobre el proceso\n",
    "                                              \n",
    "                                              n_jobs=4) # 4 nucleos del ordenador trabajando en paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizamos el modelo sobre los datos de entrenamiento, pero la comparación con el modelo sin optimizar se hará empleando el conjunto de validación, para evitar sesgar la comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 360 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 63.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 224.3min\n",
      "[Parallel(n_jobs=4)]: Done 3600 out of 3600 | elapsed: 389.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizador', TfidfVectorizer()),\n",
       "                                       ('clasificador', LogisticRegression())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'clasificador__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'clasificador__max_iter': [100, 250, 500, 1000],\n",
       "                         'clasificador__penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'clasificador__solver': ['newton-cg', 'lbfgs',\n",
       "                                                  'liblinear', 'sag', 'saga']},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "regresion_logistica_optimizada.fit(X_train, y_train) # empieza la optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el objeto con los hiperparámetros optimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado\n"
     ]
    }
   ],
   "source": [
    "guardar_modelo(regresion_logistica_optimizada, '../models/trained_models/classifiers/logit_optimizada.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos las métricas de la mejor combinación de hiperparáemtros __sobre el conjunto de validación__ para compararlo con la versión sin optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clasificador__C': 10,\n",
       " 'clasificador__max_iter': 100,\n",
       " 'clasificador__penalty': 'l2',\n",
       " 'clasificador__solver': 'saga'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta es la combinación ganadora por AUC\n",
    "regresion_logistica_optimizada.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El solver saga hace referencia al Stochastic Average Gradient Descent, en su versión ampliada para permitir la implementación de la penalización l1. En este caso, la penalización ganadorra es l2, también conocida como Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos ahora la logit con su versión optimizada. Calculamos las métricas habituales que hemos empleado a lo largo del trabajo (AUC, F1, coste del modelo...). El procedimiento es similar al del notebook de construicción de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la versión sin optimizar \n",
    "regresion_logistica = cargar_modelo('../models/trained_models/classifiers/LogisticRegression().sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionario para iterar\n",
    "modelos = {'Regresion sin optimizar': regresion_logistica,\n",
    "           'Regresion optimizada': regresion_logistica_optimizada}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion sin optimizar\n",
      "Accuracy: 0.89\n",
      "F1: 0.891\n",
      "AUC 0.956\n",
      "Tasa de falsos positivos: 12.268 %\n",
      "Ganancias de 441860 €\n",
      "--------------------------------\n",
      "Regresion optimizada\n",
      "Accuracy: 0.96\n",
      "F1: 0.897\n",
      "AUC 0.96\n",
      "Tasa de falsos positivos: 11.151 %\n",
      "Ganancias de 461790 €\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for modelo in modelos: # para cada elemento del diccionario de modelos...\n",
    "    \n",
    "    # Se extrae el calsificador acceciendo con en nombre del modelo, y\n",
    "    clasificador = modelos[modelo]\n",
    "    \n",
    "    # Si el modelo es la versión sin optimizar, se calculan sus métricas sobre test\n",
    "    if (modelo == 'Regresion sin optimizar'):\n",
    "        \n",
    "        y_pred = clasificador.predict(X_test)\n",
    "        y_pred_proba = clasificador.predict_proba(X_test)\n",
    "        \n",
    "        accuracy = clasificador.score(X_test, y_test)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "    \n",
    "        coste = coste_modelo(clasificador)\n",
    "    \n",
    "        falsos_positivos = tasa_falsos_positivos(clasificador) * 100\n",
    "        \n",
    "        print(modelo)\n",
    "        print('Accuracy:', round(accuracy, 3))\n",
    "        print('F1:', round(f1, 3))\n",
    "        print('AUC', round(auc, 3))\n",
    "        print('Tasa de falsos positivos:', round(falsos_positivos, 3), '%')\n",
    "        if (coste < 1):\n",
    "            print('Ganancias de', (-1)*coste, '€')\n",
    "        else:\n",
    "                print('Pérdidas de', coste, '€')\n",
    "        print('--------------------------------')\n",
    "    \n",
    "    # En caso contrario, si el modelo es el optimizado, sus métricas\n",
    "    # se calculan con los conjuntos de validación\n",
    "    else:\n",
    "        \n",
    "        y_pred = clasificador.predict(X_validation)\n",
    "        y_pred_proba = clasificador.predict_proba(X_validation)\n",
    "        \n",
    "        accuracy = clasificador.score(X_validation, y_validation)\n",
    "        \n",
    "        f1 = f1_score(y_validation, y_pred)\n",
    "        \n",
    "        auc = roc_auc_score(y_validation, y_pred_proba[:,1])\n",
    "    \n",
    "        coste = coste_modelo(clasificador)\n",
    "    \n",
    "        falsos_positivos = tasa_falsos_positivos(clasificador) * 100\n",
    "        \n",
    "        print(modelo)\n",
    "        print('Accuracy:', round(accuracy, 3))\n",
    "        print('F1:', round(f1, 3))\n",
    "        print('AUC', round(auc, 3))\n",
    "        print('Tasa de falsos positivos:', round(falsos_positivos, 3), '%')\n",
    "        if (coste < 1):\n",
    "            print('Ganancias de', (-1)*coste, '€')\n",
    "        else:\n",
    "                print('Pérdidas de', coste, '€')\n",
    "        print('--------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas muestran que la optimización ha sido exitosa. Todas las métricas han mejorado. Los cambios más notables son en accuracy y en tasa de falsos positivos. Se han conseguido mejorar todas las métricas, aún reduciendo la tasa de falsos positivos, en más de un 1%. Este dato podría parecer nimio, pero con los costes que se han definido para este caso de uso, el resultado son casi 20.000 € de ganancia adicional. En términos unitarios (10.000 predicciones), la mejora es de 2 € por predicción, pasando de unos ingresos unitarios de 44.18 € a 46.18 €, __un incremento en los ingresos del modelo de un 4.53%__.\n",
    "\n",
    "En síntesis, el modelo no solo supera a su versión básica en rendimiento técnico, sino también en genración de valor para la empresa, que es lo más importante.\n",
    "\n",
    "En el siguiente notebook se calculan todas las métricas del modelo optimizado y se explican los resultados del mismo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
