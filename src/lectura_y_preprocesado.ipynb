{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para limpiar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_html(texto):\n",
    "    patron_html = re.compile('<.*?>') # caracteres html\n",
    "    texto = patron_html.sub('', texto) # eliminación de los caracteres\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_emoticonos(texto):\n",
    "    \n",
    "    # Se define el patrón de emoticonos\n",
    "    patron_emojis = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticonos generales\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # símbolos\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transportes\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # banderas\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # letras chinas\n",
    "                               u\"\\U00002702-\\U000027B0\"  # resto de emoticonos\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", \n",
    "                               flags=re.UNICODE) # hay que especificar que son unicode\n",
    "    \n",
    "    # Se eliminan del texto\n",
    "    texto = patron_emojis.sub('', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_url(texto):\n",
    "    \n",
    "    # Patrón para los caracteres de URL's\n",
    "    patron_url = re.compile('https://\\S+|www\\.\\S+')\n",
    "    \n",
    "    # Eliminación del patrón\n",
    "    texto = patron_url.sub('', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_puntuacion(texto):\n",
    "    \n",
    "    # Se define el patrón para eliminar los signos de puntuación\n",
    "    patron_puntuacion = re.compile('[^\\w\\s]')\n",
    "    \n",
    "    # Se eliminan del texto\n",
    "    texto = patron_puntuacion.sub('', texto)\n",
    "    \n",
    "    # Se unifican las reseñas en un único texto para facilitar la lematizacion y tokenizacion\n",
    "    texto = ''.join(texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematizacion_y_stopwords(texto):\n",
    "    \n",
    "    # Se inicializa el lematizador\n",
    "    lematizador = WordNetLemmatizer() \n",
    "    \n",
    "    # Se utiliza una list comprehension para hacer un loop:\n",
    "    # Se genera una lista que contiene cada una de las palabras del texto, lematizadas, si \n",
    "    # estas no forman parte de las stopwords inglesas\n",
    "    texto = [lematizador.lemmatize(palabra) for palabra in texto.split() # split para tenerlo por palabras\n",
    "                                                        if palabra not in stopwords.words('english')]\n",
    "    \n",
    "    # Se unifican las reseñas, esta vez por espacios\n",
    "    texto = ' '.join(texto)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(texto):\n",
    "    \n",
    "    texto = texto.lower()\n",
    "    texto = limpiar_html(texto)\n",
    "    texto = limpiar_emoticonos(texto)\n",
    "    texto = limpiar_url(texto)\n",
    "    texto = limpiar_puntuacion(texto)\n",
    "    texto = lematizacion_y_stopwords(texto)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de preprocesado más sencillo, pensado para VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto_ligero(texto):\n",
    "    \n",
    "    texto = limpiar_html(texto)\n",
    "    texto = limpiar_url(texto)\n",
    "    \n",
    "    return texto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
