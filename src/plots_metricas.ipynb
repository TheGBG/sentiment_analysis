{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de las curvas ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_roc(modelo, \n",
    "                titulo):\n",
    "    \n",
    "    # Se calcula la predicción en términos de probabilidad\n",
    "    y_probabilidad = modelo.predict_proba(X_test)\n",
    "    \n",
    "    # Se realiza el gráfico \n",
    "    skplt.metrics.plot_roc(y_test, y_probabilidad, figsize=(12,7))\n",
    "    plt.title(titulo);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función del accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(modelo):\n",
    "    '''\n",
    "    Solo toma como arumento el modelo del que se quiere\n",
    "    calcular el accuracy. Hay que tener defindidos X_test e y_test\n",
    "    '''\n",
    "    \n",
    "    return modelo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_confusion(modelo, \n",
    "                          titulo='Matriz de cofusion',   \n",
    "                          color='Greens'):\n",
    "    '''\n",
    "    Esta función sirve para representar graficamente la matriz de confusión, con los \n",
    "    totales de erroes y aciertos de cada clase, y su normalización, que son las  tasas.\n",
    "    Tambien se puede modificar el color, que por defecto está en escala de verdes. Hay que tener \n",
    "    definido X_test e y_test\n",
    "    '''\n",
    "    prediccion = modelo.predict(X_test) # la predicción\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, prediccion) # la matriz de confusión\n",
    "    \n",
    "    # Definimos los elementos que van a ir dentro del gráfico: texto y número\n",
    "    etiquetas = ['Verdaderos negativos', 'Falsos positivos', 'Falsos negativos', 'Verdaderos positivos']\n",
    "    \n",
    "    totales = ['{0:0.0f}'.format(value) for value in\n",
    "                confusion.flatten()] # matriz 'plana'\n",
    "    \n",
    "    # Se aisla cada elemento para facilitar los calculos\n",
    "    falsos_positivos = confusion[0][1]\n",
    "    falsos_negativos = confusion[1][0]\n",
    "    verdaderos_negativos = confusion[0][0]\n",
    "    verdaderos_possitivos = confusion[1][1]\n",
    "    \n",
    "    # Se calculan las tasas\n",
    "    tasa_falsos_positivos = falsos_positivos / np.sum([falsos_positivos, verdaderos_negativos]) \n",
    "    tasa_verdaderos_negativos = 1 - tasa_falsos_positivos\n",
    "    \n",
    "    tasa_verdaderos_positivos = verdaderos_possitivos / np.sum([verdaderos_possitivos + falsos_negativos])\n",
    "    tasa_falsos_negativos = 1 - tasa_verdaderos_positivos\n",
    "    \n",
    "    # Se almacenan en una lista\n",
    "    tasas = [tasa_verdaderos_negativos, tasa_falsos_positivos,\n",
    "             tasa_falsos_negativos, tasa_verdaderos_positivos]\n",
    "    \n",
    "    # Se les da formato de porcentaje\n",
    "    porcentuales = ['{0:.2%}'.format(value) for value in tasas]\n",
    "    \n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "          zip(etiquetas, totales, porcentuales)]\n",
    "    \n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "    # Y ahora el plot\n",
    "    plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    sns.heatmap(confusion, annot=labels, fmt='', cmap=color)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel('Valor estimado')\n",
    "    plt.ylabel('Valor real'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico de la roc con el punto optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_punto_optimo (modelo,\n",
    "                      nombre_modelo,\n",
    "                      clase_positiva=1):\n",
    "        '''\n",
    "        Toma como argumentos el modelo que va a usar para los cálculos y el \n",
    "        nombre de la clase positiva. Necesario que los objetos X_test e y_test estén definidos. Hay que especificar el\n",
    "        nombre del modleo, para la etiqueta del plot\n",
    "        '''\n",
    "        \n",
    "        probabilidad_pagador = modelo.predict_proba(X_test)[:, 1] # calcula la prediccion en terminos de probabilidad\n",
    "        \n",
    "        # Valores necesarios para el cálculo\n",
    "        tasa_falsos_positivos, tasa_verdaderos_positivos, umbrales = roc_curve(y_test, \n",
    "                                                                           probabilidad_pagador, \n",
    "                                                                           pos_label=clase_positiva)\n",
    "        \n",
    "        # Media geometrica y extraccion del optimo\n",
    "        media_geometrica = np.sqrt(tasa_verdaderos_positivos * (1-tasa_falsos_positivos))\n",
    "        indice_maxima_gmean = np.argmax(media_geometrica)\n",
    "\n",
    "        # El plot \n",
    "        plt.figure(figsize=(12, 7))\n",
    "\n",
    "\n",
    "\n",
    "        plt.plot([0,1], [0,1], # es simplemente una linea recta en diagonal \n",
    "                 linestyle='--', # linea punteada\n",
    "                 color='red',\n",
    "                 label='Modelo baseline') # etiqueta de la leyenda\n",
    "\n",
    "        # Plot de la roc\n",
    "        plt.plot(tasa_falsos_positivos, # en el eje x, los falsos positivos\n",
    "                 tasa_verdaderos_positivos, # en el eje y, los verdaderos positivos\n",
    "                 marker='.',\n",
    "                 linewidth=0.1,\n",
    "                 color='darkblue',\n",
    "                 label=nombre_modelo)\n",
    "\n",
    "        # Plot del punto óptimo\n",
    "        plt.scatter(tasa_falsos_positivos[indice_maxima_gmean], # coordenada en el eje x\n",
    "                    tasa_verdaderos_positivos[indice_maxima_gmean], # coordenada en el eje y\n",
    "                    s=180, # tamaño\n",
    "                    marker='o', \n",
    "                    color='orange', \n",
    "                    label='Óptimo')\n",
    "\n",
    "        # Etiquetas \n",
    "        plt.title('Curva ROC y punto óptimo')\n",
    "        plt.xlabel('Tasa de falsos positivos')\n",
    "        plt.ylabel('Tasa de verdaderos positivos')\n",
    "        plt.legend();      \n",
    "        \n",
    "        print(f'El umbral óptimo es {round(media_geometrica[indice_maxima_gmean], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall con punto optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_punto_optimo(modelo,\n",
    "                                  nombre_modelo,\n",
    "                                  clase_positiva=1): \n",
    "    '''\n",
    "    Devuelve el gráfico de precision-recall con el punto óptimo. Necesario determinar la clase positva y \n",
    "    el nombre del modelo. Neceario que los objetos X_test e y_test estén definidos\n",
    "    \n",
    "    '''\n",
    "    probabilidad_pagador = modelo.predict_proba(X_test)[:, 1] # calcula la prediccion en terminos de probabilida\n",
    "    \n",
    "    # Se obtienen los valores de la curva \n",
    "    precision, recall, umbral = precision_recall_curve(y_test, \n",
    "                                                       probabilidad_pagador, \n",
    "                                                       pos_label=clase_positiva)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Cálculo de la Fscore\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    indice_fscore = np.argmax(fscore)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Calculamos los valores del modelo base\n",
    "    modelo_base = len(y_test[y_test == clase_positiva].dropna()) / len(y_test)\n",
    "    \n",
    "    # Plot del modelo base\n",
    "    plt.plot([0, 1], \n",
    "             [modelo_base, modelo_base], \n",
    "             linestyle='--',\n",
    "             color='red',\n",
    "             label='Modelo base')\n",
    "    \n",
    "    # Plot de los valores del XGBoost\n",
    "    plt.plot(recall, # en el eje x los valores de recall\n",
    "             precision,  # en el eje y los valores de precisión\n",
    "             marker='.',\n",
    "             color='darkblue',\n",
    "             label=nombre_modelo)\n",
    "    \n",
    "    # Plot del punto óptimo\n",
    "    plt.scatter(recall[indice_fscore], # mismo valor en cada eje\n",
    "                precision[indice_fscore], \n",
    "                s=180, \n",
    "                marker='o', \n",
    "                color='orange', \n",
    "                label='Óptimo')\n",
    "    \n",
    "    # Etiquetas de los ejes\n",
    "    plt.title('Curva Recall-Precisión')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend();\n",
    "    \n",
    "    print(f'El nivel de probabilidad que optimiza la F1  es {round(fscore[indice_fscore], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coste del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste_modelo(modelo, \n",
    "                 coste_verdaderos_negativos=100,\n",
    "                 coste_verdaderos_positivos=50,\n",
    "                 coste_falsos_positivos=300,\n",
    "                 coste_falsos_negativos=80):\n",
    "    \n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    verdaderos_negativos = matriz_confusion[0][0]\n",
    "    falsos_positivos = matriz_confusion[0][1]\n",
    "    verdaderos_positivos =  matriz_confusion[1][1]\n",
    "    falsos_negativos = matriz_confusion[1][0]\n",
    "    \n",
    "    coste = np.sum([(-1)*coste_verdaderos_negativos*verdaderos_negativos, # son perdidas que se evitan \n",
    "                    coste_falsos_negativos*falsos_negativos,\n",
    "                    (-1)*coste_verdaderos_positivos*verdaderos_positivos, # son pérdidas que se evitan\n",
    "                    coste_falsos_positivos*falsos_positivos])\n",
    "    return coste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasa de falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tasa_falsos_positivos(modelo):\n",
    "    \n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    verdaderos_negativos = matriz_confusion[0][0]\n",
    "    falsos_negativos = matriz_confusion[1][0]\n",
    "    verdaderos_positivos = matriz_confusion[1][1]\n",
    "    falsos_positivos = matriz_confusion[0][1]\n",
    "    \n",
    "    tasa_falsos_positivos = falsos_positivos / np.sum([falsos_positivos, verdaderos_negativos])\n",
    "    \n",
    "    return tasa_falsos_positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de costes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_coste(modelo, \n",
    "                          titulo='Matriz de coste',\n",
    "                          coste_verdaderos_negativos=100,\n",
    "                          coste_verdaderos_positivos=50,\n",
    "                          coste_falsos_positivos=300,\n",
    "                          coste_falsos_negativos=80,   \n",
    "                          color='RdYlGn'):\n",
    "    '''\n",
    "    Función para representar la matrizde costes\n",
    "    '''\n",
    "    prediccion = modelo.predict(X_test) # la predicción\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, prediccion) # la matriz de confusión\n",
    "    \n",
    "    # Definimos los elementos que van a ir dentro del gráfico: texto y número\n",
    "    etiquetas = ['Verdaderos negativos', 'Falsos positivos', \n",
    "                 'Falsos negativos', 'Verdaderos positivos']\n",
    "    \n",
    "    # Se aisla cada elemento para facilitar los calculos\n",
    "    falsos_positivos = confusion[0][1]\n",
    "    falsos_negativos = confusion[1][0]\n",
    "    verdaderos_negativos = confusion[0][0]\n",
    "    verdaderos_possitivos = confusion[1][1]\n",
    "    \n",
    "    # Se calculan los costes de cada clase\n",
    "    coste_total_falsos_positivos = coste_falsos_positivos * falsos_positivos\n",
    "    coste_total_falsos_negativos = coste_falsos_negativos * falsos_negativos\n",
    "    coste_total_verdaderos_positivos = (-1) * coste_verdaderos_positivos * verdaderos_possitivos\n",
    "    coste_total_verdaderos_negativos = (-1) * coste_verdaderos_negativos * verdaderos_negativos\n",
    "    \n",
    "    # Se almacenan en una lista\n",
    "    costes = [coste_total_verdaderos_negativos, coste_total_falsos_positivos,\n",
    "             coste_total_falsos_negativos, coste_total_verdaderos_positivos]\n",
    "    \n",
    "    # Formato a euros\n",
    "    coste_euros = ['{:0.0f} €'.format(value) for value in costes]\n",
    "    \n",
    "    # Formateo de las etiquetas para poder plotearlas\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in\n",
    "              zip(etiquetas, coste_euros)]\n",
    "    \n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "    # Y ahora el plot\n",
    "    plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    sns.heatmap(confusion, annot=labels, fmt='', cmap=color)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel('Valor estimado')\n",
    "    plt.ylabel('Valor real');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
